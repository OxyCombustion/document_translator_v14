# Document Translator V14 - Vertical Pipeline Architecture

## ðŸŽ¯ Quick Navigation

**Working on a specific pipeline?** Read the pipeline-specific CLAUDE file:

- ðŸ“¤ **Extraction Pipeline** (PDF â†’ JSON): [`pipelines/extraction/CLAUDE_EXTRACTION.md`](pipelines/extraction/CLAUDE_EXTRACTION.md)
- ðŸ”„ **RAG Ingestion Pipeline** (JSON â†’ JSONL + Graph): [`pipelines/rag_ingestion/CLAUDE_RAG.md`](pipelines/rag_ingestion/CLAUDE_RAG.md)
- ðŸ’¾ **Data Management Pipeline** (JSONL â†’ Vector DB): [`pipelines/data_management/CLAUDE_DATABASE.md`](pipelines/data_management/CLAUDE_DATABASE.md)
- ðŸ”§ **Shared Infrastructure** (Common standards): [`pipelines/shared/CLAUDE_SHARED.md`](pipelines/shared/CLAUDE_SHARED.md)

**New to the project?** Read this file completely, then dive into the specific pipeline you're working on.

---

## ðŸ—ï¸ Project Overview

### Mission
Extract structured content from PDF documents (equations, tables, figures, text) and prepare for RAG applications with semantic chunking, citation detection, and vector database ingestion.

### Architecture
**3 Vertical Pipelines + Shared Foundation** (21 packages total)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SHARED FOUNDATION (6 packages)                               â”‚
â”‚ common, agent_infrastructure, parallel_processing,           â”‚
â”‚ infrastructure, cli, specialized_utilities                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PIPELINE 1:  â”‚ â”‚ PIPELINE 2:   â”‚ â”‚ PIPELINE 3:      â”‚
â”‚ EXTRACTION   â”‚ â”‚ RAG INGESTION â”‚ â”‚ DATA MANAGEMENT  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PDF â†’ JSON   â”‚ â”‚ JSON â†’ JSONL  â”‚ â”‚ JSONL â†’ Vector   â”‚
â”‚ Structure    â”‚ â”‚ + Graph       â”‚ â”‚ DB + Metadata    â”‚
â”‚              â”‚ â”‚               â”‚ â”‚                  â”‚
â”‚ 7 packages   â”‚ â”‚ 5 packages    â”‚ â”‚ 4 packages       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status
- **Version**: v14 (migrated from v13)
- **Migration**: Phase 0 complete, End-to-end validation complete (2025-11-19)
- **Production Ready**: All 3 pipelines validated for single-document workflow
- **Tested**: Chapter 4 extraction (34 pages, 107 equations, 10 tables) â†’ RAG â†’ ChromaDB

---

## ðŸš€ Quick Start

### Run Complete Workflow
```bash
# Extract + RAG + Database (all 3 pipelines)
python -m cli_v14_P7 workflow --input pdfs/ --output results/
```

### Run Individual Pipelines
```bash
# Pipeline 1: Extraction only (PDF â†’ JSON)
python -m cli_v14_P7 extraction --input pdfs/ --output results/extraction/

# Pipeline 2: RAG ingestion only (JSON â†’ JSONL + Graph)
python -m cli_v14_P7 rag --input results/extraction/ --output results/rag/

# Pipeline 3: Database loading only (JSONL â†’ Vector DB)
python -m cli_v14_P7 database --input results/rag/ --output results/database/
```

### Check Pipeline Status
```bash
# Status for specific pipeline
python -m cli_v14_P7 status --pipeline extraction
python -m cli_v14_P7 status --pipeline rag
python -m cli_v14_P7 status --pipeline database
```

---

## ðŸ“Š Pipeline Architecture Details

### Pipeline 1: Extraction (7 packages)
**Mission**: Convert PDF documents to structured JSON

**Packages**:
- `extraction_v14_P1` - Main extraction orchestrator
- `detection_v14_P14` - Docling-based detection
- `docling_agents_v14_P17` - Primary processing
- `docling_agents_v14_P8` - Wrapper agents
- `specialized_extraction_v14_P15` - PyTorch YOLO detection
- `extraction_comparison_v14_P12` - Multi-method comparison
- `extraction_utilities_v14_P18` - Helper utilities

**Performance**: 98.2% extraction success (162/165 objects)

**Key Technologies**: DocLayout-YOLO, Docling, PyMuPDF

**See**: [`pipelines/extraction/CLAUDE_EXTRACTION.md`](pipelines/extraction/CLAUDE_EXTRACTION.md) for complete details

---

### Pipeline 2: RAG Ingestion (5 packages)
**Mission**: Convert structured JSON to RAG-ready JSONL bundles

**Packages**:
- `rag_v14_P2` - JSON to JSONL conversion
- `rag_extraction_v14_P16` - RAG-specific agents
- `semantic_processing_v14_P4` - Document understanding
- `chunking_v14_P10` - Semantic chunking
- `analysis_validation_v14_P19` - Quality validation

**Performance**: 34 semantic chunks, 386 citations extracted, 100% validation pass

**Key Technologies**: Semantic structure detection, citation extraction, cross-reference graphs

**See**: [`pipelines/rag_ingestion/CLAUDE_RAG.md`](pipelines/rag_ingestion/CLAUDE_RAG.md) for complete details

---

### Pipeline 3: Data Management (4 packages)
**Mission**: Load JSONL bundles into vector databases with metadata enrichment

**Packages**:
- `curation_v14_P3` - JSONL to vector DB (includes local LLM calibration)
- `database_v14_P6` - Document registry
- `metadata_v14_P13` - Zotero integration
- `relationship_detection_v14_P5` - Citation graphs

**Performance**: 100% Zotero integration safety, 42,800x speedup with extraction registry

**Key Technologies**: ChromaDB/Pinecone, Zotero, local LLM (Qwen 2.5 3B), SHA256 hashing

**See**: [`pipelines/data_management/CLAUDE_DATABASE.md`](pipelines/data_management/CLAUDE_DATABASE.md) for complete details

---

### Shared Foundation (6 packages)
**Mission**: Common infrastructure for all pipelines

**Packages**:
- `common` - Base classes and utilities
- `agent_infrastructure_v14_P8` - Agent foundation
- `parallel_processing_v14_P9` - Multi-core processing
- `infrastructure_v14_P10` - Session management
- `cli_v14_P7` - Command-line orchestrator
- `specialized_utilities_v14_P20` - Specialized tools

**See**: [`pipelines/shared/CLAUDE_SHARED.md`](pipelines/shared/CLAUDE_SHARED.md) for complete standards and patterns

---

## ðŸ› ï¸ Development Standards (Critical)

**MANDATORY**: Before writing ANY code, read:
1. [`pipelines/shared/CLAUDE_SHARED.md`](pipelines/shared/CLAUDE_SHARED.md) - Shared engineering standards
2. Pipeline-specific CLAUDE.md for your pipeline
3. `PRE_FLIGHT_CHECKLIST.md` - Complete 6-step checklist BEFORE coding

**Key Standards**:
- âœ… **UTF-8 Encoding**: MANDATORY template in every Python script
- âœ… **Module Registry Check**: Before building ANY new module
- âœ… **Proper Package Structure**: No sys.path hacks
- âœ… **Configuration-Driven**: YAML files, not hardcoded values
- âœ… **Test-Driven**: Test after EACH change (incremental development)

**Why This Exists**: Context Maintenance System audit (2025-10-23) found 9 standard violations from coding BEFORE reading standards, resulting in brittle code and 6-12 hours remediation work.

---

## ðŸ“ Repository Structure

```
document_translator_v14/
â”‚
â”œâ”€â”€ CLAUDE.md                               # This file - project overview
â”œâ”€â”€ README.md                               # Quick start guide
â”œâ”€â”€ INSTALLATION.md                         # Setup instructions
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ extraction/                         # PIPELINE 1
â”‚   â”‚   â”œâ”€â”€ CLAUDE_EXTRACTION.md            # Pipeline-specific context
â”‚   â”‚   â”œâ”€â”€ README.md                        # Quick start
â”‚   â”‚   â”œâ”€â”€ ARCHITECTURE.md                  # Design details
â”‚   â”‚   â”œâ”€â”€ packages/                        # 7 packages
â”‚   â”‚   â”œâ”€â”€ sessions/                        # Historical context
â”‚   â”‚   â”œâ”€â”€ tests/                           # Pipeline tests
â”‚   â”‚   â””â”€â”€ config/                          # Pipeline config
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_ingestion/                      # PIPELINE 2
â”‚   â”‚   â”œâ”€â”€ CLAUDE_RAG.md                   # Pipeline-specific context
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”‚   â”œâ”€â”€ packages/                        # 5 packages
â”‚   â”‚   â”œâ”€â”€ sessions/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ config/
â”‚   â”‚
â”‚   â”œâ”€â”€ data_management/                    # PIPELINE 3
â”‚   â”‚   â”œâ”€â”€ CLAUDE_DATABASE.md              # Pipeline-specific context
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”‚   â”œâ”€â”€ packages/                        # 4 packages
â”‚   â”‚   â”œâ”€â”€ sessions/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ config/
â”‚   â”‚
â”‚   â””â”€â”€ shared/                             # SHARED FOUNDATION
â”‚       â”œâ”€â”€ CLAUDE_SHARED.md                # Common standards
â”‚       â”œâ”€â”€ STANDARDS.md                     # Engineering standards
â”‚       â”œâ”€â”€ INTEGRATION.md                   # Pipeline integration
â”‚       â”œâ”€â”€ packages/                        # 6 packages
â”‚       â”œâ”€â”€ contracts/                       # Data contracts
â”‚       â””â”€â”€ tests/                           # Integration tests
â”‚
â”œâ”€â”€ docs/                                   # System-wide docs
â”‚   â”œâ”€â”€ ARCHITECTURE_OVERVIEW.md
â”‚   â”œâ”€â”€ PIPELINE_INTEGRATION_GUIDE.md
â”‚   â””â”€â”€ DEVELOPMENT_GUIDE.md
â”‚
â”œâ”€â”€ results/                                # Pipeline outputs
â”‚   â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ rag/
â”‚   â””â”€â”€ database/
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ unit/                               # Unit tests
    â”œâ”€â”€ integration/                        # Cross-pipeline tests
    â””â”€â”€ end_to_end/                         # Full workflow tests
```

---

## ðŸ”— Pipeline Integration

### Data Flow
```
PDF Document
    â†“
[PIPELINE 1: EXTRACTION]
    â†“
extraction_results.json (structured content)
    â†“
[PIPELINE 2: RAG INGESTION]
    â†“
rag_bundles.jsonl + graph.json (semantic chunks + relationships)
    â†“
[PIPELINE 3: DATA MANAGEMENT]
    â†“
Vector Database (ChromaDB/Pinecone) + Enriched Metadata
```

### Data Contracts
**Location**: `pipelines/shared/contracts/`

Each pipeline has well-defined input/output contracts:
- `extraction_output.py` - Pipeline 1 output
- `rag_input.py` - Pipeline 2 input (validates Pipeline 1 output)
- `rag_output.py` - Pipeline 2 output
- `database_input.py` - Pipeline 3 input (validates Pipeline 2 output)

**Enforcement**: Contract violations = runtime errors (fail fast)

---

## ðŸ“Š Performance Metrics

### Pipeline 1: Extraction
- **Success Rate**: 99.1% equations (107/108), 83.3% tables (10/12) - Chapter 4 validation
- **Processing Time**: ~14 minutes for 34-page document
- **Content Accuracy**: 100% for extracted objects
- **Latest Test**: Chapter 4 (34 pages, 107 equations, 10 tables extracted)

### Pipeline 2: RAG Ingestion
- **Semantic Chunks**: 34 chunks (3,833 chars/chunk avg, 130,316 total chars)
- **Citations**: 162 citations extracted (Chapter 4 validation)
- **Validation**: 100% pass rate
- **Latest Test**: 34 chunks with complete citation graphs

### Pipeline 3: Data Management
- **Ingestion Success**: 100% (34/34 chunks ingested to ChromaDB)
- **Ingestion Speed**: 39.55 chunks/second
- **Query Validation**: 100% (semantic search verified with "thermodynamic cycles")
- **Zotero Safety**: 100% (zero risk to library)
- **Registry Speedup**: 42,800x faster reuse

---

## ðŸŽ¯ v14 Production Validation (2025-11-19)

### End-to-End Testing Complete

**Validation Status**: All 3 pipelines validated with Chapter 4 (34 pages)

**Test Results**:
- âœ… **Pipeline 1 (Extraction)**: 107/108 equations (99.1%), 10/12 tables (83.3%)
- âœ… **Pipeline 2 (RAG)**: 34 semantic chunks, 130,316 chars, 162 citations
- âœ… **Pipeline 3 (Database)**: 100% ingestion success, semantic search verified

**Production Status**: All 3 pipelines production ready for single-document workflow

**Performance Highlights**:
- Extraction: 34 pages processed, 107 equations + 10 tables extracted
- RAG: 3,833 chars/chunk average, complete citation graph
- Database: 39.55 chunks/sec ingestion, ChromaDB queries validated

**Data Flow Verified**:
```
Chapter 4 PDF (34 pages)
    â†“
[PIPELINE 1] â†’ extraction_results.json (107 eqs, 10 tables)
    â†“
[PIPELINE 2] â†’ rag_bundles.jsonl (34 chunks, 162 citations)
    â†“
[PIPELINE 3] â†’ ChromaDB (34 chunks ingested, semantic search verified)
```

**Known Limitations**:
- Table extraction: 83.3% success (2 tables missed - formatting challenges)
- Single-document workflow validated (batch processing pending)
- Local LLM calibration in progress (Phase 3 pipeline)

---

## ðŸŽ¯ Current Status (2025-11-19)

### v13 â†’ v14 Migration: Phase 0 Complete + Validation Complete

**User's Strategic Decision**:
> "I want option B. I am interested in long-term stability and maintainance with accuracy as my primary goal, not speed. I also think we should move this to v14 since it is such a departure that if we screw things up can come back to this point."

**Critical Lesson from v12â†’v13**: Left 12 components behind (24% loss) - MUST NOT REPEAT

**Phase 0 Progress** (Complete):
- âœ… v13 component audit (329 Python files, 152 configs, 216 docs)
- âœ… v12 historical analysis & recovery (10/12 recovered)
- âœ… v14 directory structure created (three-pipeline architecture)
- âœ… Foundation files (READMEs, configs, 1,850+ lines documentation)
- âœ… Git repository initialized
- âœ… End-to-end validation complete (all 3 pipelines tested)
- âœ… Production validation with Chapter 4 (34 pages, 107 eqs, 10 tables)

**Validation Complete** (2025-11-19):
- âœ… Pipeline 1: 99.1% equation extraction, 83.3% table extraction
- âœ… Pipeline 2: 34 semantic chunks, 162 citations, 100% validation
- âœ… Pipeline 3: 100% ChromaDB ingestion, semantic search verified

**Timeline**: "Time is not as important as accuracy. Let's commit to finishing this correctly not quickly" âœ…

**See**: `PHASE_0_PROGRESS_SUMMARY.md` for complete session details

---

## ðŸ“š Documentation

### Essential Reading (In Order)
1. **This file (CLAUDE.md)** - Project overview
2. **Pipeline-specific CLAUDE.md** - Your pipeline context
3. **`pipelines/shared/CLAUDE_SHARED.md`** - Common standards
4. **`PRE_FLIGHT_CHECKLIST.md`** - MANDATORY before coding

### Architecture Documentation
- `V14_VERTICAL_PIPELINE_ARCHITECTURE_REVIEW.md` - Complete architecture review
- `V13_TO_V14_MIGRATION_PLAN.md` - 6-week migration plan
- `PHASE_0_PROGRESS_SUMMARY.md` - Migration progress tracking

### Session Documentation
- Extraction sessions: `pipelines/extraction/sessions/`
- RAG sessions: `pipelines/rag_ingestion/sessions/`
- Database sessions: `pipelines/data_management/sessions/`

---

## ðŸŽ¯ Quick Commands

### System Management
```bash
# Check module status
python check_module_status.py --module <name>

# Run all tests
pytest tests/

# Run specific pipeline tests
pytest tests/unit/extraction/
pytest tests/unit/rag/
pytest tests/unit/database/
```

### Development
```bash
# Install in editable mode
pip install -e .

# Run pre-commit checks
python tools/install_pre_commit_hooks.py

# Check code quality
pytest tests/
pylint src/
```

---

## ðŸŽ“ Key Concepts

### Vertical Pipeline Architecture
Each pipeline is **self-contained** with isolated context, enabling:
- âœ… **Reduced cognitive load** - Focus on one pipeline (not entire system)
- âœ… **Parallel development** - Teams work independently
- âœ… **Independent deployment** - Deploy pipelines separately
- âœ… **Easier maintenance** - Changes isolated to pipeline

### Data Contracts
Pipelines communicate via **well-defined contracts** (JSON schemas):
- âœ… **Type safety** - Validated at runtime
- âœ… **Fail fast** - Contract violations caught immediately
- âœ… **Loose coupling** - Pipelines evolve independently
- âœ… **Documentation** - Contract IS the interface

### Extract Once, Reuse Forever
Document extractions tracked in **extraction registry**:
- âœ… **SHA256 hashing** - Detects content changes
- âœ… **Multiple lookups** - PDF hash, Zotero key, DOI, title
- âœ… **42,800x speedup** - Registry lookup vs re-extraction
- âœ… **Archive preservation** - Old versions kept when methods improve

---

## ðŸš¨ Critical Success Factors

### 1. Context Isolation (Achieved)
âœ… Pipeline-specific CLAUDE.md files created (500-600 lines each)
âœ… Developers load only relevant context (not 2,611-line monolith)
âœ… 60% reduction in cognitive load

### 2. Data Contract Enforcement (Validated)
âœ… Contracts defined in `pipelines/shared/contracts/`
âœ… End-to-end validation complete (all 3 pipelines tested)
âœ… Data flow verified: PDF â†’ JSON â†’ JSONL â†’ ChromaDB

### 3. Migration Safety (Complete)
âœ… v12 component recovery (10/12 recovered)
âœ… v13 complete audit (329 files, 152 configs, 216 docs)
âœ… v14 production validation (Chapter 4, 34 pages, all 3 pipelines)

### 4. Documentation Currency (Achieved)
âœ… 5 pipeline-specific CLAUDE.md files
âœ… Complete architecture documentation
âœ… Session-specific handoffs

---

*For detailed pipeline-specific information, see the pipeline CLAUDE.md files linked at the top of this document.*

---

**Document Statistics**:
- **Total Lines**: ~500
- **Sections**: 15 main sections
- **Pipeline Links**: 4 dedicated CLAUDE.md files
- **Quick Commands**: 15+ common operations

**Last Updated**: 2025-11-19 (v14 production validation complete - all 3 pipelines tested)
