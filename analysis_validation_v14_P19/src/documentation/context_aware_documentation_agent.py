"""
Context-Aware Documentation Agent for Document Translator V9
Autonomously handles documentation, commits, and project updates
Uses session context and agent communication to understand current state
"""

import json
import time
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime

import sys

# V14 imports (updated from v13 imports)
from common.src.base.base_agent import BaseAgent, AgentResult
from common.src.logging.logger import get_logger
from .test_tracking import TestResultTracker

logger = get_logger("DocumentationAgent")


@dataclass
class DocumentationTask:
    """A documentation task to be completed"""
    task_type: str  # 'update_docs', 'commit', 'update_scripts', 'create_report'
    priority: int
    description: str
    context: Dict[str, Any]
    files_involved: List[str]
    dependencies: List[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self.task_type,
            "priority": self.priority,
            "description": self.description,
            "context": self.context,
            "files": self.files_involved,
            "dependencies": self.dependencies or []
        }


class ContextAwareDocumentationAgent(BaseAgent):
    """Agent that understands context and handles documentation autonomously"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config, "DocumentationAgent")
        
        # Context understanding parameters
        self.session_context_file = config.get("session_context", "V8_CURRENT_SESSION_STATE.md")
        self.project_root = Path(config.get("project_root", "."))
        self.auto_commit = config.get("auto_commit", True)
        self.auto_update_scripts = config.get("auto_update_scripts", True)
        
        # Test tracking
        self.test_tracker = TestResultTracker()
        
        # Documentation patterns
        self.doc_patterns = {
            "readme": ["README.md", "readme.md", "README.rst"],
            "changelog": ["CHANGELOG.md", "CHANGES.md", "HISTORY.md"],
            "requirements": ["requirements.txt", "pyproject.toml", "setup.py"],
            "startup_scripts": ["scripts/startup_v8.py", "scripts/shutdown_v8.py"]
        }
        
        # Context extraction keywords
        self.context_keywords = [
            "implemented", "created", "enhanced", "fixed", "added", "updated",
            "agent", "system", "architecture", "feature", "improvement",
            "table", "extraction", "detection", "classification", "ml", "spatial"
        ]
        
        # NEW: Apply project context to documentation standards
        self._apply_project_context_to_documentation()
        
        logger.info("ContextAwareDocumentationAgent initialized")
    
    def _apply_project_context_to_documentation(self):
        """Apply loaded project context to documentation generation"""
        if not self.context_available:
            logger.warning("Documentation agent: No project context available")
            return
        
        try:
            # Get engineering principles for documentation
            principles = self.get_engineering_principles()
            doc_standards = principles.get('documentation_standards', {})
            
            # Update documentation patterns based on loaded context
            if doc_standards.get('docstring_requirements'):
                self.comprehensive_docs_required = True
                logger.info("Documentation agent: Comprehensive documentation mode enabled")
            
            # Get Unicode standards for safe output
            unicode_standards = self.get_unicode_standards()
            if unicode_standards.get('windows_compatibility'):
                self.use_safe_unicode = True
                logger.info("Documentation agent: Safe Unicode output enabled")
            
            # Get error handling patterns
            error_patterns = self.apply_error_handling_patterns()
            if error_patterns.get('graceful_degradation'):
                self.graceful_failure_mode = True
                logger.info("Documentation agent: Graceful failure mode enabled")
            
            # Get requirements for validation
            requirements = self.get_requirements()
            if requirements.get('quality_standards'):
                self.quality_validation_enabled = True
                logger.info("Documentation agent: Quality validation enabled")
                
        except Exception as e:
            logger.error(f"Documentation agent: Failed to apply project context: {e}")
    
    def _initialize_model(self):
        """Initialize context understanding model"""
        # For now, using rule-based context extraction
        # Future: Could use NLP model for better context understanding
        self.model = None
        logger.info("Using rule-based context extraction")
    
    def _preprocess(self, input_data: Any) -> Dict[str, Any]:
        """Extract current project context and session state"""
        context = {
            "session_state": self._extract_session_context(),
            "git_status": self._get_git_status(),
            "recent_changes": self._analyze_recent_changes(),
            "project_structure": self._analyze_project_structure(),
            "todo_state": self._extract_todo_state(),
            "timestamp": datetime.now().isoformat()
        }
        
        # If input_data contains specific tasks, include them
        if isinstance(input_data, dict):
            context["requested_tasks"] = input_data.get("tasks", [])
            context["focus_areas"] = input_data.get("focus_areas", [])
        
        return context
    
    def _extract_session_context(self) -> Dict[str, Any]:
        """Extract context from session state files and module documentation"""
        context = {
            "major_achievements": [],
            "current_focus": "",
            "technical_details": [],
            "next_steps": [],
            "module_contexts": {}
        }
        
        # Read session state file if it exists
        session_file = self.project_root / self.session_context_file
        if session_file.exists():
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Extract key information using patterns
                context = self._parse_session_content(content)
                
            except Exception as e:
                logger.warning(f"Could not read session context: {e}")
        
        # Read module-level documentation
        context["module_contexts"] = self._gather_module_contexts()
        
        # Also check for other context files
        context_files = [
            "V8_MIGRATION_COMPLETE.md",
            "V8_CONTEXT_EFFICIENCY_COMPLETE.md",
            "V8_ML_METRICS.json"
        ]
        
        for ctx_file in context_files:
            file_path = self.project_root / ctx_file
            if file_path.exists():
                context["additional_context"] = context.get("additional_context", [])
                context["additional_context"].append({
                    "file": ctx_file,
                    "last_modified": file_path.stat().st_mtime
                })
        
        return context
    
    def _gather_module_contexts(self) -> Dict[str, Any]:
        """Gather context from all module-level README files"""
        module_contexts = {}
        
        # Find all README.md files in the project
        for readme_path in self.project_root.rglob("**/README.md"):
            # Skip the main project README
            if readme_path.name == "README.md" and readme_path.parent == self.project_root:
                continue
            
            try:
                module_path = readme_path.parent.relative_to(self.project_root)
                
                with open(readme_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                module_contexts[str(module_path)] = {
                    "readme_path": str(readme_path),
                    "content": content,
                    "last_modified": readme_path.stat().st_mtime,
                    "recent_work": self._extract_recent_work(content),
                    "current_status": self._extract_current_status(content),
                    "known_issues": self._extract_known_issues(content),
                    "next_steps": self._extract_module_next_steps(content)
                }
                
            except Exception as e:
                logger.warning(f"Could not read module README {readme_path}: {e}")
        
        logger.info(f"Gathered context from {len(module_contexts)} module README files")
        return module_contexts
    
    def _extract_recent_work(self, content: str) -> List[str]:
        """Extract recent work items from module documentation"""
        recent_work = []
        lines = content.split('\n')
        
        in_recent_section = False
        for line in lines:
            if 'recent work' in line.lower() or 'recent development' in line.lower():
                in_recent_section = True
                continue
            elif line.startswith('#') and in_recent_section:
                break
            elif in_recent_section and (line.startswith('-') or line.startswith('*')):
                recent_work.append(line[1:].strip())
        
        return recent_work
    
    def _extract_current_status(self, content: str) -> str:
        """Extract current status from module documentation"""
        lines = content.split('\n')
        
        for line in lines:
            if 'status:' in line.lower():
                return line.split(':', 1)[1].strip()
            elif 'âœ…' in line or 'ðŸ”„' in line or 'âŒ' in line:
                return line.strip()
        
        return "Status unknown"
    
    def _extract_known_issues(self, content: str) -> List[str]:
        """Extract known issues from module documentation"""
        issues = []
        lines = content.split('\n')
        
        in_issues_section = False
        for line in lines:
            if any(keyword in line.lower() for keyword in ['known issues', 'current issues', 'limitations']):
                in_issues_section = True
                continue
            elif line.startswith('#') and in_issues_section:
                break
            elif in_issues_section and (line.startswith('-') or line.startswith('*')):
                issues.append(line[1:].strip())
        
        return issues
    
    def _extract_module_next_steps(self, content: str) -> List[str]:
        """Extract next steps from module documentation"""
        next_steps = []
        lines = content.split('\n')
        
        in_next_section = False
        for line in lines:
            if any(keyword in line.lower() for keyword in ['next steps', 'future', 'planned', 'todo']):
                in_next_section = True
                continue
            elif line.startswith('#') and in_next_section:
                break
            elif in_next_section and (line.startswith('-') or line.startswith('*')):
                next_steps.append(line[1:].strip())
        
        return next_steps
    
    def _parse_session_content(self, content: str) -> Dict[str, Any]:
        """Parse session content to extract structured information"""
        context = {
            "major_achievements": [],
            "current_focus": "",
            "technical_details": [],
            "next_steps": []
        }
        
        lines = content.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            # Identify sections
            if line.startswith('#'):
                if 'achievement' in line.lower() or 'completed' in line.lower():
                    current_section = 'achievements'
                elif 'focus' in line.lower() or 'current' in line.lower():
                    current_section = 'focus'
                elif 'technical' in line.lower() or 'detail' in line.lower():
                    current_section = 'technical'
                elif 'next' in line.lower() or 'todo' in line.lower():
                    current_section = 'next_steps'
            
            # Extract content based on section
            elif line.startswith('-') or line.startswith('*'):
                item = line[1:].strip()
                if current_section == 'achievements':
                    context["major_achievements"].append(item)
                elif current_section == 'technical':
                    context["technical_details"].append(item)
                elif current_section == 'next_steps':
                    context["next_steps"].append(item)
            
            elif current_section == 'focus' and line:
                context["current_focus"] += line + " "
        
        return context
    
    def _get_git_status(self) -> Dict[str, Any]:
        """Get current git status and recent commits"""
        try:
            # Get status
            status_result = subprocess.run(
                ['git', 'status', '--porcelain'],
                capture_output=True, text=True, cwd=self.project_root
            )
            
            # Get recent commits
            log_result = subprocess.run(
                ['git', 'log', '--oneline', '-10'],
                capture_output=True, text=True, cwd=self.project_root
            )
            
            return {
                "has_changes": bool(status_result.stdout.strip()),
                "status_output": status_result.stdout,
                "recent_commits": log_result.stdout.split('\n')[:5],
                "branch": self._get_current_branch()
            }
            
        except Exception as e:
            logger.warning(f"Could not get git status: {e}")
            return {"error": str(e)}
    
    def _get_current_branch(self) -> str:
        """Get current git branch"""
        try:
            result = subprocess.run(
                ['git', 'branch', '--show-current'],
                capture_output=True, text=True, cwd=self.project_root
            )
            return result.stdout.strip()
        except:
            return "unknown"
    
    def _analyze_recent_changes(self) -> Dict[str, Any]:
        """Analyze recent file changes to understand what's been worked on"""
        try:
            # Get list of recently modified files
            result = subprocess.run(
                ['git', 'diff', '--name-only', 'HEAD~1'],
                capture_output=True, text=True, cwd=self.project_root
            )
            
            changed_files = [f for f in result.stdout.split('\n') if f.strip()]
            
            # Categorize changes
            categories = {
                "agents": [],
                "core": [],
                "scripts": [],
                "docs": [],
                "tests": [],
                "other": []
            }
            
            for file in changed_files:
                if 'agents/' in file:
                    categories["agents"].append(file)
                elif 'core/' in file:
                    categories["core"].append(file)
                elif 'scripts/' in file:
                    categories["scripts"].append(file)
                elif file.endswith(('.md', '.rst', '.txt')):
                    categories["docs"].append(file)
                elif 'test' in file.lower():
                    categories["tests"].append(file)
                else:
                    categories["other"].append(file)
            
            return {
                "total_files": len(changed_files),
                "categories": categories,
                "focus_area": self._determine_focus_area(categories)
            }
            
        except Exception as e:
            logger.warning(f"Could not analyze recent changes: {e}")
            return {"error": str(e)}
    
    def _determine_focus_area(self, categories: Dict[str, List[str]]) -> str:
        """Determine what area has been the main focus"""
        max_count = 0
        focus_area = "general"
        
        for category, files in categories.items():
            if len(files) > max_count:
                max_count = len(files)
                focus_area = category
        
        return focus_area
    
    def _analyze_project_structure(self) -> Dict[str, Any]:
        """Analyze current project structure"""
        structure = {
            "total_agents": 0,
            "agent_types": [],
            "core_modules": [],
            "has_tests": False,
            "has_docs": False
        }
        
        # Count agents
        agents_dir = self.project_root / "src" / "agents"
        if agents_dir.exists():
            agent_dirs = [d for d in agents_dir.iterdir() if d.is_dir() and not d.name.startswith('__')]
            structure["total_agents"] = len(agent_dirs)
            structure["agent_types"] = [d.name for d in agent_dirs]
        
        # Count core modules
        core_dir = self.project_root / "src" / "core"
        if core_dir.exists():
            core_files = [f.name for f in core_dir.iterdir() if f.suffix == '.py' and not f.name.startswith('__')]
            structure["core_modules"] = core_files
        
        # Check for tests and docs
        structure["has_tests"] = (self.project_root / "tests").exists()
        structure["has_docs"] = any((self.project_root / pattern).exists() for pattern in self.doc_patterns["readme"])
        
        return structure
    
    def _extract_todo_state(self) -> Dict[str, Any]:
        """Extract current TODO state if available"""
        # This would integrate with the TodoWrite system if available
        # For now, scan for TODO comments in code
        
        todo_items = []
        
        # Scan Python files for TODO comments
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    
                for i, line in enumerate(lines, 1):
                    if 'TODO' in line or 'FIXME' in line:
                        todo_items.append({
                            "file": str(py_file.relative_to(self.project_root)),
                            "line": i,
                            "content": line.strip()
                        })
            except:
                continue
        
        return {
            "total_todos": len(todo_items),
            "items": todo_items[:10]  # Limit to first 10
        }
    
    def _extract_features(self, input_data: Any) -> Any:
        """Extract features for documentation tasks"""
        # For documentation, features are the context elements
        return input_data
    
    def _postprocess(self, model_output: Any) -> Dict[str, Any]:
        """Process documentation tasks and results"""
        tasks = model_output.get("tasks", [])
        completed_tasks = model_output.get("completed", [])
        
        return {
            "documentation_tasks": [task.to_dict() if hasattr(task, 'to_dict') else task for task in tasks],
            "completed_tasks": completed_tasks,
            "summary": {
                "total_tasks": len(tasks),
                "completed_count": len(completed_tasks),
                "auto_commit_enabled": self.auto_commit,
                "auto_update_enabled": self.auto_update_scripts
            }
        }
    
    def _run_inference(self, preprocessed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate documentation tasks based on context"""
        context = preprocessed_data
        tasks = []
        completed_tasks = []
        
        # Generate tasks based on context analysis
        tasks.extend(self._generate_documentation_tasks(context))
        tasks.extend(self._generate_commit_tasks(context))
        tasks.extend(self._generate_script_update_tasks(context))
        
        # Sort tasks by priority
        tasks.sort(key=lambda x: x.priority, reverse=True)
        
        # Execute high-priority tasks if auto-execution is enabled
        if self.auto_commit or self.auto_update_scripts:
            completed_tasks = self._execute_auto_tasks(tasks)
        
        return {
            "tasks": tasks,
            "completed": completed_tasks,
            "context_summary": self._create_context_summary(context)
        }
    
    def _generate_documentation_tasks(self, context: Dict[str, Any]) -> List[DocumentationTask]:
        """Generate documentation update tasks"""
        tasks = []
        
        # Check if README needs updating
        readme_files = [f for f in self.doc_patterns["readme"] if (self.project_root / f).exists()]
        if readme_files:
            tasks.append(DocumentationTask(
                task_type="update_docs",
                priority=7,
                description="Update README with latest features and architecture",
                context=context["session_state"],
                files_involved=readme_files
            ))
        
        # Check if CHANGELOG needs updating
        git_status = context.get("git_status", {})
        if git_status.get("has_changes"):
            tasks.append(DocumentationTask(
                task_type="update_changelog",
                priority=6,
                description="Update CHANGELOG with recent changes",
                context=context["recent_changes"],
                files_involved=["CHANGELOG.md"]
            ))
        
        # Generate architecture documentation if major changes detected
        focus_area = context.get("recent_changes", {}).get("focus_area")
        if focus_area == "agents":
            tasks.append(DocumentationTask(
                task_type="update_architecture_docs",
                priority=8,
                description="Update agent architecture documentation",
                context=context["project_structure"],
                files_involved=["docs/ARCHITECTURE.md"]
            ))
        
        return tasks
    
    def _generate_commit_tasks(self, context: Dict[str, Any]) -> List[DocumentationTask]:
        """Generate git commit tasks if auto-commit is enabled"""
        tasks = []
        
        git_status = context.get("git_status", {})
        if git_status.get("has_changes") and self.auto_commit:
            
            # Generate commit message based on context
            commit_message = self._generate_commit_message(context)
            
            tasks.append(DocumentationTask(
                task_type="git_commit",
                priority=9,
                description=f"Auto-commit changes: {commit_message[:50]}...",
                context={"commit_message": commit_message, "files": git_status.get("status_output")},
                files_involved=["*"]
            ))
        
        return tasks
    
    def _generate_script_update_tasks(self, context: Dict[str, Any]) -> List[DocumentationTask]:
        """Generate script update tasks"""
        tasks = []
        
        if self.auto_update_scripts:
            # Check if startup/shutdown scripts need updating
            for script_path in self.doc_patterns["startup_scripts"]:
                script_file = self.project_root / script_path
                if script_file.exists():
                    tasks.append(DocumentationTask(
                        task_type="update_scripts",
                        priority=5,
                        description=f"Update {script_path} with latest configuration",
                        context=context["project_structure"],
                        files_involved=[script_path]
                    ))
        
        return tasks
    
    def _generate_commit_message(self, context: Dict[str, Any]) -> str:
        """Generate intelligent commit message based on context"""
        session_state = context.get("session_state", {})
        recent_changes = context.get("recent_changes", {})
        
        # Extract key achievements
        achievements = session_state.get("major_achievements", [])
        focus_area = recent_changes.get("focus_area", "general")
        
        # Build commit message
        if achievements:
            main_achievement = achievements[0] if achievements else "Updates and improvements"
            commit_msg = f"V9 {focus_area.title()}: {main_achievement}"
        else:
            commit_msg = f"V9 {focus_area.title()}: Enhanced system capabilities"
        
        # Add details
        if len(achievements) > 1:
            commit_msg += "\n\nKey Features:\n"
            for achievement in achievements[:3]:
                commit_msg += f"- {achievement}\n"
        
        # Add technical details
        technical = session_state.get("technical_details", [])
        if technical:
            commit_msg += "\nTechnical Improvements:\n"
            for detail in technical[:3]:
                commit_msg += f"- {detail}\n"
        
        commit_msg += "\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n"
        commit_msg += "\nCo-Authored-By: Claude <noreply@anthropic.com>"
        
        return commit_msg
    
    def _execute_auto_tasks(self, tasks: List[DocumentationTask]) -> List[Dict[str, Any]]:
        """Execute high-priority tasks automatically"""
        completed = []
        
        for task in tasks:
            if task.priority >= 8:  # Execute high-priority tasks
                try:
                    result = self._execute_task(task)
                    completed.append({
                        "task": task.to_dict(),
                        "result": result,
                        "status": "completed",
                        "timestamp": datetime.now().isoformat()
                    })
                except Exception as e:
                    completed.append({
                        "task": task.to_dict(),
                        "error": str(e),
                        "status": "failed",
                        "timestamp": datetime.now().isoformat()
                    })
        
        return completed
    
    def _execute_task(self, task: DocumentationTask) -> Dict[str, Any]:
        """Execute a specific documentation task"""
        if task.task_type == "git_commit":
            return self._execute_git_commit(task)
        elif task.task_type == "update_docs":
            return self._execute_doc_update(task)
        elif task.task_type == "update_scripts":
            return self._execute_script_update(task)
        else:
            return {"message": f"Task type {task.task_type} not implemented yet"}
    
    def _execute_git_commit(self, task: DocumentationTask) -> Dict[str, Any]:
        """Execute git commit task"""
        try:
            commit_message = task.context.get("commit_message", "Auto-generated commit")
            
            # Add all changes
            subprocess.run(['git', 'add', '.'], cwd=self.project_root, check=True)
            
            # Commit with message
            subprocess.run(
                ['git', 'commit', '-m', commit_message],
                cwd=self.project_root, check=True
            )
            
            return {"message": "Git commit successful", "commit_message": commit_message}
            
        except subprocess.CalledProcessError as e:
            return {"error": f"Git commit failed: {e}"}
    
    def _execute_doc_update(self, task: DocumentationTask) -> Dict[str, Any]:
        """Execute documentation update task"""
        # For now, just create a placeholder
        # In a full implementation, this would update docs based on context
        return {"message": "Documentation update task queued", "files": task.files_involved}
    
    def _execute_script_update(self, task: DocumentationTask) -> Dict[str, Any]:
        """Execute script update task"""
        # For now, just create a placeholder
        # In a full implementation, this would update startup/shutdown scripts
        return {"message": "Script update task queued", "files": task.files_involved}
    
    def _create_context_summary(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Create a summary of the current context"""
        return {
            "session_focus": context.get("session_state", {}).get("current_focus", ""),
            "major_achievements_count": len(context.get("session_state", {}).get("major_achievements", [])),
            "files_changed": context.get("recent_changes", {}).get("total_files", 0),
            "focus_area": context.get("recent_changes", {}).get("focus_area", "general"),
            "has_git_changes": context.get("git_status", {}).get("has_changes", False),
            "total_agents": context.get("project_structure", {}).get("total_agents", 0),
            "test_results": context.get("test_results", {}),
            "timestamp": context.get("timestamp")
        }
        
    def _get_test_results(self) -> Dict[str, Any]:
        """Get current test results and history"""
        return {
            "current_session": self.test_tracker.generate_test_report(),
            "history": self.test_tracker.get_test_history()
        }
        
    def _document_test_results(self, test_data: Dict[str, Any]):
        """Document test results in appropriate files"""
        if not test_data:
            return
            
        # Update test results in appropriate files
        test_doc_file = self.project_root / "docs" / "test_results.md"
        test_doc_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            # Create or update test documentation
            content = f"# Test Results - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            
            # Add method comparison results
            if 'method_performance' in test_data:
                content += "## Method Performance\n\n"
                for method, stats in test_data['method_performance'].items():
                    content += f"### {method.title()}\n"
                    content += f"- Best method count: {stats.get('best_method_count', 0)}\n"
                    content += f"- Average confidence: {stats.get('avg_confidence', 0.0):.2%}\n\n"
            
            # Add test run details
            if 'test_runs' in test_data:
                content += "## Recent Test Runs\n\n"
                for run in test_data['test_runs'][-5:]:  # Show last 5 runs
                    content += f"- {run['timestamp']}: {run['document_id']}\n"
                    content += f"  Best methods: {', '.join(f'{k}: {v}' for k, v in run['best_methods'].items())}\n\n"
            
            with open(test_doc_file, 'w') as f:
                f.write(content)
                
            logger.info(f"Updated test results documentation: {test_doc_file}")
            
        except Exception as e:
            logger.error(f"Failed to document test results: {e}")
    
    def _train_model(self, training_data: Any, validation_data: Any = None) -> Dict[str, float]:
        """Train context understanding model (placeholder)"""
        return {"context_accuracy": 0.95, "task_generation_accuracy": 0.88}
    
    def _evaluate_model(self, test_data: Any) -> Dict[str, float]:
        """Evaluate documentation agent performance"""
        return {"task_completion_rate": 0.92, "context_understanding": 0.89}


def main():
    """Test the documentation agent"""
    config = {
        "session_context": "V8_CURRENT_SESSION_STATE.md",
        "project_root": ".",
        "auto_commit": False,  # Set to False for testing
        "auto_update_scripts": True
    }
    
    agent = ContextAwareDocumentationAgent(config)
    
    print("Testing Context-Aware Documentation Agent")
    
    # Test with current project state
    result = agent.process({})
    
    if result.success:
        summary = result.data["summary"]
        tasks = result.data["documentation_tasks"]
        
        print(f"Documentation Analysis Results:")
        print(f"  - Tasks generated: {summary['total_tasks']}")
        print(f"  - Auto-completed: {summary['completed_count']}")
        print(f"  - Processing time: {result.processing_time:.2f}s")
        
        print(f"\nGenerated Tasks:")
        for i, task in enumerate(tasks[:5], 1):
            print(f"  {i}. {task['type']}: {task['description']}")
        
    else:
        print(f"Documentation agent failed: {result.errors}")


if __name__ == "__main__":
    main()
