# Three-Pipeline Architecture Migration Plan

**Document Version**: 1.0
**Date**: 2025-11-14
**Author**: Web Claude Code (Anthropic)
**For Review By**: Local Claude Code
**Project**: Document Translator v13 Architecture Refactoring

---

## üéØ Executive Summary

**Vision**: Split the monolithic document translator v13 system into three vertically-separated pipelines with clear interface boundaries to reduce context complexity for AI development agents and enable parallel development.

**Strategic Rationale**: By reducing context from ~1,500 lines (single CLAUDE.md) to ~500 lines per pipeline, we enable AI agents like Claude Code to work more efficiently on focused tasks without needing to understand the entire system.

**Expected Benefits**:
- üß† **Context Reduction**: 3x smaller context per development session
- üöÄ **Development Velocity**: Parallel development on independent pipelines
- üîí **Isolation**: Changes in one pipeline don't break others
- üß™ **Testing**: Pipeline-specific tests without end-to-end dependencies
- üìö **Maintainability**: Clear ownership and documentation boundaries

**Timeline**: 4-5 weeks for complete migration
**Risk Level**: MEDIUM (interface contracts are critical success factor)

---

## üìê Current vs Proposed Architecture

### Current Architecture (Monolithic)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Document Translator v13 (Single Monolith)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Extraction  ‚îÇ ‚Üí ‚îÇ Relationship ‚îÇ ‚Üí ‚îÇ  Curation    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Agents     ‚îÇ   ‚îÇ  Detection   ‚îÇ   ‚îÇ  & Quality   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  All components share:                                   ‚îÇ
‚îÇ  - Single CLAUDE.md (~1,500 lines)                       ‚îÇ
‚îÇ  - Tightly coupled imports                               ‚îÇ
‚îÇ  - Shared configuration                                  ‚îÇ
‚îÇ  - End-to-end testing only                               ‚îÇ
‚îÇ                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Problems**:
- ‚ùå AI agents must load full 1,500-line context for small changes
- ‚ùå Changes to extraction can accidentally break RAG or curation
- ‚ùå Cannot work on pipelines in parallel
- ‚ùå Testing requires full system setup

---

### Proposed Architecture (Three Vertical Pipelines)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pipeline 1: EXTRACTION                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Context: extraction_CLAUDE.md (~500 lines)                      ‚îÇ
‚îÇ Input:  PDF documents                                           ‚îÇ
‚îÇ Output: extraction_results.json (INTERFACE v1.0)                ‚îÇ
‚îÇ Scope:  Object detection, extraction, image processing          ‚îÇ
‚îÇ Tests:  tests/pipeline1/ (no Pipeline 2/3 dependencies)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì (JSON interface)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pipeline 2: RAG PREPARATION                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Context: rag_CLAUDE.md (~500 lines)                             ‚îÇ
‚îÇ Input:  extraction_results.json                                 ‚îÇ
‚îÇ Output: rag_bundles.jsonl, knowledge_graph.json (INTERFACE v1.0)‚îÇ
‚îÇ Scope:  Relationships, embeddings, semantic bundling            ‚îÇ
‚îÇ Tests:  tests/pipeline2/ (mock extraction input)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì (JSONL + JSON interfaces)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pipeline 3: CURATION & QUALITY                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Context: curation_CLAUDE.md (~500 lines)                        ‚îÇ
‚îÇ Input:  rag_bundles.jsonl, knowledge_graph.json                 ‚îÇ
‚îÇ Output: model_metadata_*.db, curated_indices.json               ‚îÇ
‚îÇ Scope:  Novelty detection, multi-model evaluation, tracking     ‚îÇ
‚îÇ Tests:  tests/pipeline3/ (mock RAG input)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits**:
- ‚úÖ AI agents load only 500 lines of relevant context
- ‚úÖ Strict JSON interfaces prevent accidental breakage
- ‚úÖ Parallel development on all three pipelines
- ‚úÖ Pipeline-specific testing with mocked inputs

---

## üèóÔ∏è Detailed Pipeline Specifications

### Pipeline 1: Extraction

**Purpose**: Extract structured objects from PDF documents

**Input**:
- PDF documents: `data/{document_name}.pdf`

**Output**:
- `results/extraction/{document_id}/extraction_results.json` (v1.0 schema)
- Extracted images: `results/extraction/{document_id}/{type}/`
  - `equations/` - PNG images of equations
  - `tables/` - PNG images of tables
  - `figures/` - PNG images of figures

**Components** (to be moved/refactored):
```
pipeline1_extraction/
‚îú‚îÄ‚îÄ CLAUDE.md (extraction-specific context)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detection/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unified_detection_module.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docling_table_detector.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ figure_intelligence_analyzer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extraction/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ equation_extraction_agent.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ table_extraction_agent.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ figure_extraction_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ core/
‚îÇ       ‚îî‚îÄ‚îÄ extraction_registry.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_detection.py
‚îÇ   ‚îú‚îÄ‚îÄ test_extraction.py
‚îÇ   ‚îî‚îÄ‚îÄ test_extraction_output_schema.py
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ extraction_config.yaml
```

**Dependencies**:
- PyMuPDF (PDF processing)
- Docling (table detection)
- DocLayout-YOLO (object detection)
- OpenCV (image processing)
- **NO dependencies on Pipeline 2 or 3**

**Key Responsibilities**:
1. Detect objects in PDFs (equations, tables, figures, text)
2. Extract objects with high-quality images
3. Generate standardized JSON output
4. Track extraction history in extraction_registry.json

---

### Pipeline 2: RAG Preparation

**Purpose**: Build relationships, generate embeddings, create RAG-ready bundles

**Input**:
- `results/extraction/{document_id}/extraction_results.json`

**Output**:
- `results/rag/{document_id}/rag_bundles.jsonl` (one bundle per line)
- `results/rag/{document_id}/knowledge_graph.json`
- `results/rag/{document_id}/bundle_statistics.json`

**Components** (to be moved/refactored):
```
pipeline2_rag/
‚îú‚îÄ‚îÄ CLAUDE.md (RAG-specific context)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_registry.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reference_resolver.py
‚îÇ   ‚îú‚îÄ‚îÄ detectors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variable_definition_detector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_dependency_detector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cross_reference_detector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ citation_detector.py
‚îÇ   ‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ relationship_validator.py
‚îÇ   ‚îî‚îÄ‚îÄ exporters/
‚îÇ       ‚îú‚îÄ‚îÄ rag_micro_bundle_generator.py
‚îÇ       ‚îú‚îÄ‚îÄ context_enhancer.py
‚îÇ       ‚îî‚îÄ‚îÄ knowledge_graph_builder.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_relationship_detection.py
‚îÇ   ‚îú‚îÄ‚îÄ test_bundle_generation.py
‚îÇ   ‚îî‚îÄ‚îÄ test_rag_output_schema.py
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ relationship_extraction/
    ‚îî‚îÄ‚îÄ rag/
```

**Dependencies**:
- sentence-transformers (for embeddings)
- NetworkX (for knowledge graph)
- spaCy or similar (for NLP)
- **NO dependencies on Pipeline 1 or 3**

**Key Responsibilities**:
1. Detect relationships between extracted objects
2. Validate dimensional consistency
3. Generate embeddings for semantic search
4. Build knowledge graph with typed edges
5. Create self-contained RAG bundles

---

### Pipeline 3: Curation & Quality

**Purpose**: Evaluate novelty, track quality, curate for specific AI models

**Input**:
- `results/rag/{document_id}/rag_bundles.jsonl`
- `results/rag/{document_id}/knowledge_graph.json`

**Output**:
- `results/curation/model_metadata_{model_id}.db` (SQLite)
- `results/curation/curated_indices.json`
- `results/curation/quality_metrics.json`

**Components** (to be moved/refactored):
```
pipeline3_curation/
‚îú‚îÄ‚îÄ CLAUDE.md (curation-specific context)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ novelty_metadata_database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_llm_novelty_classifier.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_confidence_calibrator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ domain_specificity_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ novelty_validation.py
‚îÇ   ‚îî‚îÄ‚îÄ exporters/
‚îÇ       ‚îî‚îÄ‚îÄ curated_index_builder.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_novelty_classification.py
‚îÇ   ‚îú‚îÄ‚îÄ test_calibration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_curation_output_schema.py
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ curation_config.yaml
```

**Dependencies**:
- transformers (for local LLM - Qwen 2.5 3B)
- SQLite (for metadata storage)
- PyTorch (for LLM inference)
- **NO dependencies on Pipeline 1 or 2**

**Key Responsibilities**:
1. Classify novelty of content for specific models
2. Calibrate LLM confidence scores
3. Track quality metrics across models
4. Generate curated indices for model-specific RAG
5. Manage metadata staleness and expiration

---

## üìã Interface Specifications

### Interface 1: extraction_results.json (Pipeline 1 ‚Üí 2)

**Schema Version**: 1.0
**File Format**: JSON
**Location**: `results/extraction/{document_id}/extraction_results.json`

**Complete Schema**:
```json
{
  "schema_version": "1.0",
  "document_metadata": {
    "document_id": "ch04_heat_transfer",
    "source_pdf": "data/Ch-04_Heat_Transfer.pdf",
    "source_pdf_hash": "sha256:abc123...",
    "extraction_timestamp": "2025-11-14T10:00:00Z",
    "extractor_version": "v13.1.0",
    "total_pages": 34
  },
  "extracted_objects": {
    "equations": [
      {
        "id": "eq:1",
        "type": "equation",
        "content": "q = -kA dT/dx",
        "latex": "q = -kA \\frac{dT}{dx}",
        "page": 1,
        "bbox": {
          "x": 120,
          "y": 450,
          "width": 300,
          "height": 40
        },
        "image_path": "results/extraction/ch04_heat_transfer/equations/eq_001.png",
        "confidence": 0.95,
        "detection_method": "doclayout_yolo"
      }
    ],
    "tables": [
      {
        "id": "tbl:1",
        "type": "table",
        "title": "Thermal Conductivity of Materials",
        "page": 5,
        "bbox": {
          "x": 80,
          "y": 200,
          "width": 450,
          "height": 300
        },
        "image_path": "results/extraction/ch04_heat_transfer/tables/tbl_001.png",
        "data_path": "results/extraction/ch04_heat_transfer/tables/tbl_001.xlsx",
        "rows": 15,
        "columns": 4,
        "confidence": 0.88,
        "detection_method": "docling"
      }
    ],
    "figures": [
      {
        "id": "fig:1",
        "type": "figure",
        "caption": "Heat transfer through a plane wall",
        "page": 3,
        "bbox": {
          "x": 100,
          "y": 250,
          "width": 400,
          "height": 350
        },
        "image_path": "results/extraction/ch04_heat_transfer/figures/fig_001.png",
        "confidence": 0.92,
        "detection_method": "doclayout_yolo"
      }
    ],
    "text_chunks": [
      {
        "id": "txt:1",
        "type": "text",
        "content": "Fourier's law of heat conduction states that...",
        "page": 1,
        "bbox": {
          "x": 80,
          "y": 100,
          "width": 450,
          "height": 200
        },
        "word_count": 156,
        "char_count": 782
      }
    ]
  },
  "extraction_statistics": {
    "total_objects": 165,
    "equations": 108,
    "tables": 13,
    "figures": 44,
    "text_chunks": 250,
    "processing_time_seconds": 42.8,
    "success_rate": 0.982
  }
}
```

**Validation Rules**:
- ‚úÖ `schema_version` must be "1.0"
- ‚úÖ All `id` fields must be unique within type
- ‚úÖ All `bbox` coordinates must be positive
- ‚úÖ All `image_path` files must exist
- ‚úÖ All `confidence` scores must be 0.0-1.0
- ‚úÖ `source_pdf_hash` must match actual PDF hash

**Breaking Changes Policy**:
- Adding new fields: MINOR version bump (1.0 ‚Üí 1.1) - backward compatible
- Renaming/removing fields: MAJOR version bump (1.0 ‚Üí 2.0) - breaking change
- Pipeline 2 must support 1.x versions with graceful degradation

---

### Interface 2: rag_bundles.jsonl (Pipeline 2 ‚Üí 3)

**Schema Version**: 1.0
**File Format**: JSON Lines (one object per line)
**Location**: `results/rag/{document_id}/rag_bundles.jsonl`

**Bundle Schema** (per line):
```json
{
  "bundle_id": "eq:1_bundle",
  "bundle_type": "equation",
  "schema_version": "1.0",
  "created_timestamp": "2025-11-14T10:05:00Z",
  "source_object": {
    "id": "eq:1",
    "type": "equation",
    "content": "q = -kA dT/dx",
    "latex": "q = -kA \\frac{dT}{dx}",
    "page": 1
  },
  "relationships": [
    {
      "relationship_id": "vardef:1",
      "type": "DEFINES_VARIABLE",
      "target_id": "var:q",
      "metadata": {
        "variable": "q",
        "definition": "heat flux (W/m¬≤)"
      }
    }
  ],
  "embeddings": {
    "model": "all-MiniLM-L6-v2",
    "vector": [0.123, -0.456, 0.789, ...],  // 384 dimensions
    "vector_hash": "sha256:def456..."
  },
  "context_enhancement": {
    "usage_guidance": "This is Fourier's law for one-dimensional heat conduction...",
    "semantic_tags": ["heat_transfer", "conduction", "fouriers_law"],
    "related_bundles": ["tbl:3_bundle", "fig:1_bundle"]
  },
  "metadata": {
    "token_count": 42,
    "char_count": 156,
    "quality_score": 0.95
  }
}
```

**Validation Rules**:
- ‚úÖ Each line must be valid JSON
- ‚úÖ `bundle_id` must be unique across file
- ‚úÖ `embeddings.vector` must have correct dimensions
- ‚úÖ All `target_id` references must exist in knowledge graph
- ‚úÖ `bundle_type` must be one of: equation, table, figure, concept

---

### Interface 3: knowledge_graph.json (Pipeline 2 ‚Üí 3)

**Schema Version**: 1.0
**File Format**: JSON
**Location**: `results/rag/{document_id}/knowledge_graph.json`

**Graph Schema**:
```json
{
  "schema_version": "1.0",
  "document_id": "ch04_heat_transfer",
  "created_timestamp": "2025-11-14T10:05:00Z",
  "nodes": [
    {
      "id": "eq:1",
      "type": "equation",
      "label": "Fourier's Law",
      "page": 1,
      "metadata": {
        "content": "q = -kA dT/dx",
        "latex": "q = -kA \\frac{dT}{dx}"
      }
    },
    {
      "id": "var:q",
      "type": "variable",
      "label": "heat flux (q)",
      "metadata": {
        "symbol": "q",
        "name": "heat flux",
        "units": "W/m¬≤",
        "dimension": "ML/T¬≥"
      }
    },
    {
      "id": "tbl:3",
      "type": "table",
      "label": "Emissivity Values",
      "page": 8,
      "metadata": {
        "rows": 20,
        "columns": 3
      }
    }
  ],
  "edges": [
    {
      "id": "rel:1",
      "source": "eq:1",
      "target": "var:q",
      "type": "DEFINES_VARIABLE",
      "confidence": 0.98,
      "metadata": {
        "role": "output",
        "equation_position": "left_hand_side"
      }
    },
    {
      "id": "rel:2",
      "source": "eq:9",
      "target": "tbl:3",
      "type": "REQUIRES_DATA_FROM",
      "confidence": 0.95,
      "metadata": {
        "variable": "epsilon",
        "lookup_method": "select_by_material"
      }
    }
  ],
  "statistics": {
    "total_nodes": 250,
    "total_edges": 297,
    "node_types": {
      "equation": 108,
      "table": 13,
      "figure": 44,
      "variable": 78,
      "reference": 7
    },
    "edge_types": {
      "DEFINES_VARIABLE": 156,
      "REQUIRES_DATA_FROM": 45,
      "REFERENCES": 89,
      "CITES": 7
    }
  }
}
```

**Validation Rules**:
- ‚úÖ All `edges.source` must reference existing `nodes.id`
- ‚úÖ All `edges.target` must reference existing `nodes.id`
- ‚úÖ No self-loops (source ‚â† target)
- ‚úÖ No duplicate edges (same source, target, type)
- ‚úÖ Edge types must be from defined set

---

## üìã Shared Infrastructure

### Common Library Structure

**Purpose**: Shared utilities used by all three pipelines

**Location**: `common/`

**Components**:
```
common/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ pdf_utils.py          # PDF reading, hashing
‚îú‚îÄ‚îÄ config_loader.py      # YAML configuration loading
‚îú‚îÄ‚îÄ logging_setup.py      # Structured logging
‚îú‚îÄ‚îÄ file_utils.py         # Path handling, file operations
‚îú‚îÄ‚îÄ hash_utils.py         # SHA256 hashing for content
‚îú‚îÄ‚îÄ validation_utils.py   # Schema validation helpers
‚îî‚îÄ‚îÄ exceptions.py         # Shared exception types
```

**Versioning**: Common library has independent semantic versioning

**Example Usage**:
```python
# In Pipeline 1
from common.pdf_utils import compute_pdf_hash
from common.config_loader import load_config

# In Pipeline 2
from common.logging_setup import setup_logger
from common.validation_utils import validate_json_schema

# In Pipeline 3
from common.hash_utils import compute_content_hash
from common.exceptions import ValidationError
```

**Critical Rule**: Common library must have NO dependencies on pipeline-specific code

---

## üóìÔ∏è Migration Plan (4-5 Weeks)

### Week 1: Foundation & Interface Definition

**Goal**: Define all interfaces and create validation infrastructure

**Tasks**:

#### Day 1-2: Interface Schema Definition
- [ ] **Task 1.1**: Create `schemas/` directory
- [ ] **Task 1.2**: Write `extraction_results_v1.json` JSON Schema
- [ ] **Task 1.3**: Write `rag_bundles_v1.json` JSON Schema
- [ ] **Task 1.4**: Write `knowledge_graph_v1.json` JSON Schema
- [ ] **Task 1.5**: Document versioning policy in `INTERFACE_VERSIONING.md`

**Deliverables**:
```
schemas/
‚îú‚îÄ‚îÄ extraction_results_v1.json
‚îú‚îÄ‚îÄ rag_bundles_v1.json
‚îú‚îÄ‚îÄ knowledge_graph_v1.json
‚îî‚îÄ‚îÄ README.md (versioning policy)
```

#### Day 3-4: Validation Infrastructure
- [ ] **Task 1.6**: Create `validate_interfaces.py` script
- [ ] **Task 1.7**: Implement Pydantic models for each schema
- [ ] **Task 1.8**: Write validation tests (`test_schema_validation.py`)
- [ ] **Task 1.9**: Create mock data generators for testing

**Deliverables**:
```
common/
‚îú‚îÄ‚îÄ schemas.py (Pydantic models)
‚îî‚îÄ‚îÄ validation_utils.py (validation functions)

tests/
‚îî‚îÄ‚îÄ test_interface_validation.py
```

#### Day 5: Shared Library Setup
- [ ] **Task 1.10**: Create `common/` directory structure
- [ ] **Task 1.11**: Move shared utilities to `common/`
- [ ] **Task 1.12**: Add `pyproject.toml` for common library
- [ ] **Task 1.13**: Write tests for common utilities

**Deliverables**:
```
common/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ pdf_utils.py
‚îú‚îÄ‚îÄ config_loader.py
‚îú‚îÄ‚îÄ logging_setup.py
‚îî‚îÄ‚îÄ pyproject.toml

tests/common/
‚îî‚îÄ‚îÄ test_common_utils.py
```

---

### Week 2: Pipeline 1 (Extraction) Migration

**Goal**: Isolate extraction components into Pipeline 1

**Tasks**:

#### Day 1: Directory Restructuring
- [ ] **Task 2.1**: Create `pipeline1_extraction/` directory
- [ ] **Task 2.2**: Move detection agents to `pipeline1_extraction/src/agents/detection/`
- [ ] **Task 2.3**: Move extraction agents to `pipeline1_extraction/src/agents/extraction/`
- [ ] **Task 2.4**: Move extraction tests to `pipeline1_extraction/tests/`

**Deliverables**:
```
pipeline1_extraction/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ agents/
‚îÇ       ‚îú‚îÄ‚îÄ detection/
‚îÇ       ‚îî‚îÄ‚îÄ extraction/
‚îî‚îÄ‚îÄ tests/
```

#### Day 2-3: Output Standardization
- [ ] **Task 2.5**: Create `ExtractionResultsBuilder` class
- [ ] **Task 2.6**: Update all extraction agents to use builder
- [ ] **Task 2.7**: Add schema validation to output generation
- [ ] **Task 2.8**: Test output format against schema

**Deliverables**:
```python
# pipeline1_extraction/src/output_builder.py
class ExtractionResultsBuilder:
    """Build standardized extraction_results.json output."""

    def add_equation(self, eq_data: dict) -> None: ...
    def add_table(self, tbl_data: dict) -> None: ...
    def add_figure(self, fig_data: dict) -> None: ...
    def build(self) -> dict: ...
    def validate(self) -> bool: ...
    def save(self, output_path: str) -> None: ...
```

#### Day 4: Pipeline 1 CLAUDE.md
- [ ] **Task 2.9**: Create `pipeline1_extraction/CLAUDE.md`
- [ ] **Task 2.10**: Extract extraction-specific content from main CLAUDE.md
- [ ] **Task 2.11**: Document input/output contracts
- [ ] **Task 2.12**: Add troubleshooting guide

**Deliverables**:
```
pipeline1_extraction/
‚îî‚îÄ‚îÄ CLAUDE.md (~500 lines, extraction-focused)
```

#### Day 5: Testing & Validation
- [ ] **Task 2.13**: Run full extraction pipeline on Chapter 4
- [ ] **Task 2.14**: Validate output against schema
- [ ] **Task 2.15**: Fix any validation errors
- [ ] **Task 2.16**: Document test results

**Success Criteria**:
- ‚úÖ Chapter 4 extraction produces valid `extraction_results.json`
- ‚úÖ All tests pass
- ‚úÖ No dependencies on Pipeline 2 or 3 code

---

### Week 3: Pipeline 2 (RAG) Migration

**Goal**: Isolate RAG components into Pipeline 2

**Tasks**:

#### Day 1: Directory Restructuring
- [ ] **Task 3.1**: Create `pipeline2_rag/` directory
- [ ] **Task 3.2**: Move relationship detectors to `pipeline2_rag/src/detectors/`
- [ ] **Task 3.3**: Move exporters to `pipeline2_rag/src/exporters/`
- [ ] **Task 3.4**: Move RAG tests to `pipeline2_rag/tests/`

**Deliverables**:
```
pipeline2_rag/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ detectors/
‚îÇ   ‚îú‚îÄ‚îÄ exporters/
‚îÇ   ‚îî‚îÄ‚îÄ core/
‚îî‚îÄ‚îÄ tests/
```

#### Day 2-3: Input/Output Standardization
- [ ] **Task 3.5**: Create `ExtractionResultsReader` class (reads Pipeline 1 output)
- [ ] **Task 3.6**: Create `RAGBundleWriter` class (writes JSONL)
- [ ] **Task 3.7**: Create `KnowledgeGraphBuilder` class (builds graph JSON)
- [ ] **Task 3.8**: Add schema validation to all outputs

**Deliverables**:
```python
# pipeline2_rag/src/io_handlers.py
class ExtractionResultsReader:
    """Read and validate Pipeline 1 output."""
    def __init__(self, json_path: str): ...
    def validate(self) -> bool: ...
    def get_equations(self) -> List[dict]: ...
    def get_tables(self) -> List[dict]: ...
    def get_figures(self) -> List[dict]: ...

class RAGBundleWriter:
    """Write standardized RAG bundles."""
    def write_bundle(self, bundle: dict) -> None: ...
    def validate_bundle(self, bundle: dict) -> bool: ...
    def finalize(self) -> str: ...
```

#### Day 4: Pipeline 2 CLAUDE.md
- [ ] **Task 3.9**: Create `pipeline2_rag/CLAUDE.md`
- [ ] **Task 3.10**: Extract RAG-specific content from main CLAUDE.md
- [ ] **Task 3.11**: Document relationship detection logic
- [ ] **Task 3.12**: Add embedding generation guide

**Deliverables**:
```
pipeline2_rag/
‚îî‚îÄ‚îÄ CLAUDE.md (~500 lines, RAG-focused)
```

#### Day 5: Testing with Mock Data
- [ ] **Task 3.13**: Create mock `extraction_results.json` for testing
- [ ] **Task 3.14**: Run Pipeline 2 with mock input
- [ ] **Task 3.15**: Validate outputs against schemas
- [ ] **Task 3.16**: Test with real Pipeline 1 output from Week 2

**Success Criteria**:
- ‚úÖ Pipeline 2 runs successfully with mock input
- ‚úÖ Pipeline 2 processes real Chapter 4 extraction output
- ‚úÖ All outputs pass schema validation
- ‚úÖ No dependencies on Pipeline 1 or 3 code

---

### Week 4: Pipeline 3 (Curation) Migration

**Goal**: Isolate curation components into Pipeline 3

**Tasks**:

#### Day 1: Directory Restructuring
- [ ] **Task 4.1**: Create `pipeline3_curation/` directory
- [ ] **Task 4.2**: Move novelty classification to `pipeline3_curation/src/core/`
- [ ] **Task 4.3**: Move validation to `pipeline3_curation/src/validators/`
- [ ] **Task 4.4**: Move curation tests to `pipeline3_curation/tests/`

**Deliverables**:
```
pipeline3_curation/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îî‚îÄ‚îÄ exporters/
‚îî‚îÄ‚îÄ tests/
```

#### Day 2-3: Input/Output Standardization
- [ ] **Task 4.5**: Create `RAGBundleReader` class (reads Pipeline 2 output)
- [ ] **Task 4.6**: Create `KnowledgeGraphReader` class
- [ ] **Task 4.7**: Update database schema for pipeline architecture
- [ ] **Task 4.8**: Add metadata tracking for pipeline provenance

**Deliverables**:
```python
# pipeline3_curation/src/io_handlers.py
class RAGBundleReader:
    """Read and process RAG bundles from Pipeline 2."""
    def __init__(self, jsonl_path: str): ...
    def validate(self) -> bool: ...
    def iter_bundles(self) -> Iterator[dict]: ...
    def get_bundle_by_id(self, bundle_id: str) -> dict: ...

class KnowledgeGraphReader:
    """Read knowledge graph from Pipeline 2."""
    def __init__(self, json_path: str): ...
    def validate(self) -> bool: ...
    def get_nodes(self) -> List[dict]: ...
    def get_edges(self) -> List[dict]: ...
```

#### Day 4: Pipeline 3 CLAUDE.md
- [ ] **Task 4.9**: Create `pipeline3_curation/CLAUDE.md`
- [ ] **Task 4.10**: Extract curation-specific content from main CLAUDE.md
- [ ] **Task 4.11**: Document novelty classification logic
- [ ] **Task 4.12**: Add calibration layer documentation

**Deliverables**:
```
pipeline3_curation/
‚îî‚îÄ‚îÄ CLAUDE.md (~500 lines, curation-focused)
```

#### Day 5: Testing with Mock Data
- [ ] **Task 4.13**: Create mock `rag_bundles.jsonl` for testing
- [ ] **Task 4.14**: Run Pipeline 3 with mock input
- [ ] **Task 4.15**: Validate database outputs
- [ ] **Task 4.16**: Test with real Pipeline 2 output from Week 3

**Success Criteria**:
- ‚úÖ Pipeline 3 runs successfully with mock input
- ‚úÖ Pipeline 3 processes real Chapter 4 RAG output
- ‚úÖ Database schema includes pipeline provenance
- ‚úÖ No dependencies on Pipeline 1 or 2 code

---

### Week 5: Integration Testing & Documentation

**Goal**: Validate end-to-end pipeline and finalize documentation

**Tasks**:

#### Day 1-2: End-to-End Integration Testing
- [ ] **Task 5.1**: Run full three-pipeline sequence on Chapter 4
- [ ] **Task 5.2**: Validate all intermediate outputs
- [ ] **Task 5.3**: Compare results with monolithic version
- [ ] **Task 5.4**: Measure performance (time, memory)

**Test Sequence**:
```bash
# Pipeline 1: Extraction
cd pipeline1_extraction
python run_extraction.py --input data/Ch-04_Heat_Transfer.pdf \
    --output results/extraction/ch04/

# Validate Pipeline 1 output
python validate_extraction_output.py results/extraction/ch04/extraction_results.json

# Pipeline 2: RAG Preparation
cd ../pipeline2_rag
python run_rag_preparation.py \
    --input results/extraction/ch04/extraction_results.json \
    --output results/rag/ch04/

# Validate Pipeline 2 output
python validate_rag_output.py results/rag/ch04/

# Pipeline 3: Curation
cd ../pipeline3_curation
python run_curation.py \
    --input results/rag/ch04/rag_bundles.jsonl \
    --model qwen-2.5-3b \
    --output results/curation/

# Validate Pipeline 3 output
python validate_curation_output.py results/curation/model_metadata_qwen-2.5-3b.db
```

#### Day 3: Documentation Finalization
- [ ] **Task 5.5**: Write `PIPELINE_ARCHITECTURE_OVERVIEW.md`
- [ ] **Task 5.6**: Create developer quickstart guides for each pipeline
- [ ] **Task 5.7**: Document interface versioning policy
- [ ] **Task 5.8**: Write troubleshooting guide

**Deliverables**:
```
docs/
‚îú‚îÄ‚îÄ PIPELINE_ARCHITECTURE_OVERVIEW.md
‚îú‚îÄ‚îÄ PIPELINE1_QUICKSTART.md
‚îú‚îÄ‚îÄ PIPELINE2_QUICKSTART.md
‚îú‚îÄ‚îÄ PIPELINE3_QUICKSTART.md
‚îú‚îÄ‚îÄ INTERFACE_VERSIONING.md
‚îî‚îÄ‚îÄ TROUBLESHOOTING.md
```

#### Day 4: Cleanup & Migration
- [ ] **Task 5.9**: Archive old monolithic code to `archive/v13_monolithic/`
- [ ] **Task 5.10**: Update root CLAUDE.md to reference pipeline structure
- [ ] **Task 5.11**: Create `run_full_pipeline.sh` orchestration script
- [ ] **Task 5.12**: Update CI/CD configuration (if applicable)

**Deliverables**:
```
archive/
‚îî‚îÄ‚îÄ v13_monolithic/
    ‚îî‚îÄ‚îÄ [all old code]

scripts/
‚îî‚îÄ‚îÄ run_full_pipeline.sh
```

#### Day 5: Final Validation & Sign-off
- [ ] **Task 5.13**: Run complete pipeline on 3 different documents
- [ ] **Task 5.14**: Validate all outputs
- [ ] **Task 5.15**: Performance benchmarking report
- [ ] **Task 5.16**: Create migration completion checklist

**Success Criteria**:
- ‚úÖ All three pipelines run independently
- ‚úÖ End-to-end integration produces correct results
- ‚úÖ Performance comparable to monolithic version (¬±10%)
- ‚úÖ All documentation complete
- ‚úÖ All tests passing

---

## üéØ Success Criteria & Validation

### Technical Success Criteria

1. **Interface Contracts** ‚úÖ
   - [ ] All interfaces have JSON schemas
   - [ ] All outputs pass schema validation
   - [ ] Interface versions documented

2. **Code Isolation** ‚úÖ
   - [ ] No cross-pipeline imports (except common/)
   - [ ] Each pipeline has independent tests
   - [ ] Each pipeline can run standalone

3. **Context Reduction** ‚úÖ
   - [ ] Each CLAUDE.md file ‚â§ 600 lines
   - [ ] 60% reduction from monolithic (~1,500 lines)
   - [ ] No duplicate content across files

4. **Functionality Preservation** ‚úÖ
   - [ ] Chapter 4 extraction: 165 objects (same as before)
   - [ ] RAG bundles: 120 bundles (same as before)
   - [ ] Curation: Same accuracy (95-97%)

5. **Performance** ‚úÖ
   - [ ] Pipeline 1: ‚â§ 60 seconds (was ~45s)
   - [ ] Pipeline 2: ‚â§ 90 seconds (was ~70s)
   - [ ] Pipeline 3: ‚â§ 20 seconds (was ~15s)
   - [ ] Total: ‚â§ 180 seconds (10% overhead acceptable)

### Development Success Criteria

6. **AI Agent Efficiency** ‚úÖ
   - [ ] Local Claude can work on one pipeline with <600 line context
   - [ ] Changes to one pipeline don't require understanding others
   - [ ] Mock data enables pipeline development without dependencies

7. **Parallel Development** ‚úÖ
   - [ ] Multiple developers can work on different pipelines simultaneously
   - [ ] Interface changes require explicit coordination
   - [ ] Pipeline-specific tests enable independent validation

8. **Maintainability** ‚úÖ
   - [ ] Clear ownership boundaries
   - [ ] Interface versioning enables evolution
   - [ ] Shared utilities prevent code duplication

---

## ‚ö†Ô∏è Risk Management

### Risk 1: Interface Breaking Changes

**Risk Level**: HIGH
**Probability**: MEDIUM
**Impact**: HIGH

**Scenario**: Pipeline 1 developer changes output format, breaking Pipeline 2

**Mitigation**:
1. **Semantic Versioning**: All interfaces use semver (v1.0, v1.1, v2.0)
2. **Schema Validation**: Automated tests validate outputs
3. **Deprecation Policy**:
   - v1.x supported for 6 months after v2.0 release
   - Pipeline 2 must support both v1.x and v2.x during transition
4. **Change Review Process**: Interface changes require review from all pipeline owners

**Detection**:
```python
# Automated in CI/CD
def test_interface_compatibility():
    # Pipeline 1 produces v1.0 output
    extraction_output = run_pipeline1()
    assert validate_schema(extraction_output, "extraction_results_v1.json")

    # Pipeline 2 can consume v1.0 input
    rag_output = run_pipeline2(extraction_output)
    assert rag_output is not None  # Didn't crash
```

---

### Risk 2: Shared Library Coupling

**Risk Level**: MEDIUM
**Probability**: HIGH
**Impact**: MEDIUM

**Scenario**: Common library becomes bloated with pipeline-specific code

**Mitigation**:
1. **Clear Scope**: Common library only for truly shared utilities (PDF, logging, config)
2. **Code Review**: Any addition to common/ requires justification
3. **Size Limit**: Common library ‚â§ 1,000 lines total
4. **No Pipeline Logic**: Common library has zero business logic

**Enforcement**:
```python
# Pre-commit hook
def check_common_library_size():
    total_lines = count_lines("common/")
    if total_lines > 1000:
        raise Error("Common library exceeds 1,000 lines")
```

---

### Risk 3: Testing Gaps

**Risk Level**: MEDIUM
**Probability**: MEDIUM
**Impact**: HIGH

**Scenario**: Pipeline changes pass individual tests but break integration

**Mitigation**:
1. **Unit Tests**: Each pipeline has comprehensive unit tests
2. **Integration Tests**: Weekly end-to-end pipeline runs
3. **Mock Data**: Standardized mock data for all interfaces
4. **Regression Suite**: Chapter 4 as regression test baseline

**Test Coverage Goals**:
- Pipeline 1: 85% code coverage
- Pipeline 2: 90% code coverage
- Pipeline 3: 85% code coverage
- Common library: 95% code coverage

---

### Risk 4: Documentation Drift

**Risk Level**: LOW
**Probability**: HIGH
**Impact**: MEDIUM

**Scenario**: CLAUDE.md files become outdated as code evolves

**Mitigation**:
1. **Documentation Review**: Update CLAUDE.md with every major change
2. **Automated Checks**: Link code examples in docs to actual code
3. **Quarterly Review**: Review all CLAUDE.md files every 3 months
4. **Version Tags**: Tag CLAUDE.md with code version

**Example**:
```markdown
<!-- In pipeline1_extraction/CLAUDE.md -->
# Current Version: v13.2.0
# Last Updated: 2025-11-14

## Quick Start
[Code example verified against v13.2.0]
```

---

## üìä Performance Benchmarks

### Baseline (Monolithic Architecture)

**Test Document**: Chapter 4 Heat Transfer (34 pages, 165 objects)

```
Extraction:     42.8 seconds
RAG Prep:       68.3 seconds
Curation:       14.2 seconds
-----------------------------------
Total:          125.3 seconds
```

### Target (Pipeline Architecture)

**Acceptable Overhead**: ‚â§10% (137.8 seconds max)

**Expected Performance**:
```
Pipeline 1:     50 seconds   (+17%)  # Overhead from schema validation
Pipeline 2:     75 seconds   (+10%)  # Overhead from interface I/O
Pipeline 3:     18 seconds   (+27%)  # Overhead from additional validation
-----------------------------------
Total:          143 seconds  (+14%)  # Slightly above target

Optimizations planned:
- Lazy validation (only in debug mode)
- Binary format for large embeddings
- Caching of intermediate results

Optimized Target: 130 seconds (+4%)
```

---

## üîÑ Rollback Plan

**Scenario**: Pipeline architecture proves problematic

**Rollback Steps**:

1. **Archive Pipeline Code** (1 hour)
   ```bash
   mv pipeline1_extraction archive/pipeline_attempt_2025-11/
   mv pipeline2_rag archive/pipeline_attempt_2025-11/
   mv pipeline3_curation archive/pipeline_attempt_2025-11/
   ```

2. **Restore Monolithic Code** (30 minutes)
   ```bash
   git checkout v13_monolithic_backup
   # Or restore from archive/v13_monolithic/
   ```

3. **Restore CLAUDE.md** (15 minutes)
   ```bash
   cp archive/v13_monolithic/CLAUDE.md ./
   ```

4. **Validation** (30 minutes)
   - Run full test suite
   - Process Chapter 4 end-to-end
   - Verify outputs match pre-migration baseline

**Total Rollback Time**: 2-3 hours

**Rollback Criteria** (when to abort):
- ‚ùå Interface validation overhead >20%
- ‚ùå Cannot achieve <600 lines per CLAUDE.md
- ‚ùå Integration testing fails repeatedly
- ‚ùå Development velocity decreases (not increases)

---

## üìã Detailed Task Checklist

### Week 1: Foundation (15 tasks)
- [ ] 1.1: Create schemas/ directory
- [ ] 1.2: Write extraction_results_v1.json schema
- [ ] 1.3: Write rag_bundles_v1.json schema
- [ ] 1.4: Write knowledge_graph_v1.json schema
- [ ] 1.5: Document versioning policy
- [ ] 1.6: Create validate_interfaces.py
- [ ] 1.7: Implement Pydantic models
- [ ] 1.8: Write validation tests
- [ ] 1.9: Create mock data generators
- [ ] 1.10: Create common/ directory
- [ ] 1.11: Move shared utilities
- [ ] 1.12: Add pyproject.toml
- [ ] 1.13: Write common/ tests
- [ ] 1.14: Update .gitignore
- [ ] 1.15: Week 1 validation checkpoint

### Week 2: Pipeline 1 (16 tasks)
- [ ] 2.1: Create pipeline1_extraction/ directory
- [ ] 2.2: Move detection agents
- [ ] 2.3: Move extraction agents
- [ ] 2.4: Move extraction tests
- [ ] 2.5: Create ExtractionResultsBuilder
- [ ] 2.6: Update agents to use builder
- [ ] 2.7: Add output schema validation
- [ ] 2.8: Test output format
- [ ] 2.9: Create pipeline1 CLAUDE.md
- [ ] 2.10: Extract content from main CLAUDE.md
- [ ] 2.11: Document I/O contracts
- [ ] 2.12: Add troubleshooting guide
- [ ] 2.13: Run extraction on Chapter 4
- [ ] 2.14: Validate output
- [ ] 2.15: Fix validation errors
- [ ] 2.16: Week 2 validation checkpoint

### Week 3: Pipeline 2 (16 tasks)
- [ ] 3.1: Create pipeline2_rag/ directory
- [ ] 3.2: Move relationship detectors
- [ ] 3.3: Move exporters
- [ ] 3.4: Move RAG tests
- [ ] 3.5: Create ExtractionResultsReader
- [ ] 3.6: Create RAGBundleWriter
- [ ] 3.7: Create KnowledgeGraphBuilder
- [ ] 3.8: Add output validation
- [ ] 3.9: Create pipeline2 CLAUDE.md
- [ ] 3.10: Extract RAG content
- [ ] 3.11: Document relationship logic
- [ ] 3.12: Add embedding guide
- [ ] 3.13: Create mock extraction input
- [ ] 3.14: Run with mock input
- [ ] 3.15: Validate outputs
- [ ] 3.16: Week 3 validation checkpoint

### Week 4: Pipeline 3 (16 tasks)
- [ ] 4.1: Create pipeline3_curation/ directory
- [ ] 4.2: Move novelty classification
- [ ] 4.3: Move validators
- [ ] 4.4: Move curation tests
- [ ] 4.5: Create RAGBundleReader
- [ ] 4.6: Create KnowledgeGraphReader
- [ ] 4.7: Update database schema
- [ ] 4.8: Add pipeline provenance
- [ ] 4.9: Create pipeline3 CLAUDE.md
- [ ] 4.10: Extract curation content
- [ ] 4.11: Document classification logic
- [ ] 4.12: Add calibration docs
- [ ] 4.13: Create mock RAG input
- [ ] 4.14: Run with mock input
- [ ] 4.15: Validate database
- [ ] 4.16: Week 4 validation checkpoint

### Week 5: Integration (16 tasks)
- [ ] 5.1: Run full pipeline on Chapter 4
- [ ] 5.2: Validate all outputs
- [ ] 5.3: Compare with monolithic
- [ ] 5.4: Performance benchmarks
- [ ] 5.5: Write architecture overview
- [ ] 5.6: Create quickstart guides
- [ ] 5.7: Document versioning
- [ ] 5.8: Write troubleshooting guide
- [ ] 5.9: Archive old code
- [ ] 5.10: Update root CLAUDE.md
- [ ] 5.11: Create orchestration script
- [ ] 5.12: Update CI/CD
- [ ] 5.13: Run on 3 documents
- [ ] 5.14: Final validation
- [ ] 5.15: Performance report
- [ ] 5.16: Migration completion checklist

**Total Tasks**: 79

---

## üéØ Next Steps for Discussion

### Questions for Local Claude Code

1. **Timeline Feasibility**:
   - Does 4-5 weeks seem realistic?
   - Should we add buffer time?
   - Any tasks that seem underestimated?

2. **Interface Design**:
   - Are the proposed JSON schemas appropriate?
   - Should we use binary formats for embeddings (performance)?
   - Any missing fields in the schemas?

3. **Testing Strategy**:
   - Is mock data approach sufficient?
   - Should we create a test document (smaller than Chapter 4)?
   - What level of test coverage is realistic?

4. **Migration Risks**:
   - What risks are we missing?
   - How should we handle rollback scenario?
   - Should we migrate incrementally (one pipeline at a time)?

5. **Development Workflow**:
   - Should we create separate git branches for each pipeline?
   - How to coordinate interface changes?
   - What review process for CLAUDE.md updates?

### Proposed Decision Points

**Decision Point 1** (Week 1): Approve interface schemas
- Review all three JSON schemas
- Validate against current data
- Sign off on v1.0 contracts

**Decision Point 2** (Week 2): Validate Pipeline 1 isolation
- Confirm Pipeline 1 runs independently
- Review extraction_results.json quality
- Approve CLAUDE.md structure

**Decision Point 3** (Week 3): Validate Pipeline 2 isolation
- Confirm Pipeline 2 works with Pipeline 1 output
- Review RAG bundle quality
- Check knowledge graph completeness

**Decision Point 4** (Week 4): Validate Pipeline 3 isolation
- Confirm Pipeline 3 works with Pipeline 2 output
- Review curation quality
- Verify database schema

**Decision Point 5** (Week 5): Final migration approval
- Review end-to-end performance
- Compare with monolithic baseline
- Make go/no-go decision

---

## üìö Reference Documentation

### Architecture Documents to Create

1. **PIPELINE_ARCHITECTURE_OVERVIEW.md**: High-level architecture explanation
2. **INTERFACE_VERSIONING.md**: Semantic versioning policy for interfaces
3. **PIPELINE1_QUICKSTART.md**: How to work on extraction pipeline
4. **PIPELINE2_QUICKSTART.md**: How to work on RAG pipeline
5. **PIPELINE3_QUICKSTART.md**: How to work on curation pipeline
6. **TROUBLESHOOTING.md**: Common issues and solutions
7. **MIGRATION_COMPLETION_CHECKLIST.md**: Final validation checklist

### Code Standards

1. **Interface Contracts**: All I/O must validate against schemas
2. **Error Handling**: Validation errors must include helpful messages
3. **Logging**: All pipelines use structured logging (JSON format)
4. **Configuration**: All pipelines use YAML configuration
5. **Testing**: Minimum 85% code coverage per pipeline

### Documentation Standards

1. **CLAUDE.md Structure**:
   - Purpose (50 lines)
   - Current Session (100 lines)
   - Architecture (150 lines)
   - Input/Output Contracts (100 lines)
   - Troubleshooting (100 lines)
   - **Total**: ~500 lines

2. **Code Comments**:
   - Every function has docstring
   - Complex logic has inline comments
   - Magic numbers explained

3. **Interface Documentation**:
   - Every field in schema has description
   - Examples for each interface
   - Validation rules documented

---

## ‚úÖ Sign-off Checklist

### Pre-Migration Sign-off (Before Week 1)
- [ ] User approves overall plan
- [ ] User approves 4-5 week timeline
- [ ] User approves pipeline boundaries
- [ ] User approves interface design approach
- [ ] Local Claude Code reviews plan
- [ ] Local Claude Code approves task breakdown
- [ ] Resources allocated (AI agent time, user review time)

### Post-Migration Sign-off (After Week 5)
- [ ] All 79 tasks completed
- [ ] All interfaces validated
- [ ] All tests passing
- [ ] Performance benchmarks met
- [ ] Documentation complete
- [ ] User accepts final deliverables
- [ ] Migration officially complete

---

## üìù Appendix: Template Files

### Template: extraction_results.json
```json
{
  "schema_version": "1.0",
  "document_metadata": {
    "document_id": "example_doc",
    "source_pdf": "data/example.pdf",
    "source_pdf_hash": "sha256:...",
    "extraction_timestamp": "2025-11-14T10:00:00Z",
    "extractor_version": "v13.1.0",
    "total_pages": 10
  },
  "extracted_objects": {
    "equations": [],
    "tables": [],
    "figures": [],
    "text_chunks": []
  },
  "extraction_statistics": {
    "total_objects": 0,
    "processing_time_seconds": 0.0,
    "success_rate": 1.0
  }
}
```

### Template: rag_bundles.jsonl
```json
{"bundle_id": "example_bundle", "bundle_type": "equation", "schema_version": "1.0", "source_object": {...}, "relationships": [], "embeddings": {...}, "context_enhancement": {...}, "metadata": {...}}
```

### Template: knowledge_graph.json
```json
{
  "schema_version": "1.0",
  "document_id": "example_doc",
  "created_timestamp": "2025-11-14T10:00:00Z",
  "nodes": [],
  "edges": [],
  "statistics": {
    "total_nodes": 0,
    "total_edges": 0
  }
}
```

---

**Document Status**: READY FOR REVIEW
**Next Action**: Local Claude Code to review and provide feedback
**Review Deadline**: Within 48 hours of document creation

**Prepared by**: Web Claude Code (Anthropic)
**Date**: 2025-11-14
**Version**: 1.0
