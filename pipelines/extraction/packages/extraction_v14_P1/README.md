# Pipeline 1: Extraction (extraction_v14_P1)

**Purpose**: PDF â†’ Structured JSON

**Input**: Raw PDF documents
**Output**: `extraction_results_v1.json` (equations, tables, figures, text with bboxes)

## ğŸ¯ Responsibilities

### **Detection**
- YOLO-based object detection (equations, figures, tables)
- Docling structural analysis
- PyMuPDF text extraction
- Hybrid multi-method detection

### **Extraction**
- Equation extraction (bidirectional, parallel)
- Table extraction (text-based, vision-based)
- Figure extraction (image crops, captions)
- Text extraction (semantic chunking)

### **Validation**
- Bounding box validation
- Content completeness checking
- Duplicate detection
- Quality scoring

## ğŸ“ Directory Structure

```
extraction_v14_P1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ detection/         # Detection agents
â”‚   â”‚   â”‚   â”œâ”€â”€ yolo_detector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ docling_detector.py
â”‚   â”‚   â”‚   â””â”€â”€ pymupdf_detector.py
â”‚   â”‚   â””â”€â”€ extraction/        # Extraction agents
â”‚   â”‚       â”œâ”€â”€ equation_extractor.py
â”‚   â”‚       â”œâ”€â”€ table_extractor.py
â”‚   â”‚       â”œâ”€â”€ figure_extractor.py
â”‚   â”‚       â””â”€â”€ text_extractor.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ pipeline.py        # Main extraction pipeline
â”‚   â”‚   â”œâ”€â”€ validator.py       # Output validation
â”‚   â”‚   â””â”€â”€ schema.py          # Data models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ bbox_utils.py      # Bounding box utilities
â”‚       â”œâ”€â”€ image_utils.py     # Image processing
â”‚       â””â”€â”€ parallel_utils.py  # Multi-core processing
â”œâ”€â”€ config/
â”‚   â””â”€â”€ extraction_v14_P1_config.yaml
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_detection.py
â”‚   â”œâ”€â”€ test_extraction.py
â”‚   â””â”€â”€ test_integration.py
â””â”€â”€ docs/
    â”œâ”€â”€ detection_methods.md
    â”œâ”€â”€ extraction_methods.md
    â””â”€â”€ schema_reference.md
```

## ğŸ”§ Recovered v12 Components

These working components from v12 will be integrated into this pipeline:

1. **bidirectional_equation_extractor.py** (17K)
   - Handles equation numbers before OR after mathematical content
   - Scoring algorithm for equation quality
   - Multi-line equation support

2. **parallel_equation_extractor.py** (21K)
   - Multi-core CPU optimization
   - Batch processing for page arrays
   - 1.9x speedup with perfect accuracy preservation

3. **parallel_table_extractor.py** (15K)
   - Multi-core table extraction
   - Batch processing optimization
   - Proven accuracy match to sequential

## ğŸ“Š Output Schema

### `extraction_results_v1.json`

```json
{
  "metadata": {
    "document_id": "string",
    "filename": "string",
    "pages": "integer",
    "extraction_date": "ISO-8601",
    "pipeline_version": "extraction_v14_P1",
    "schema_version": "v1"
  },
  "equations": [
    {
      "equation_id": "string",
      "page": "integer",
      "bbox": {"x0": "float", "y0": "float", "x1": "float", "y1": "float"},
      "content": "string",
      "latex": "string",
      "confidence": "float",
      "extraction_method": "string"
    }
  ],
  "tables": [
    {
      "table_id": "string",
      "page": "integer",
      "bbox": {...},
      "headers": ["string"],
      "rows": [["string"]],
      "markdown": "string",
      "confidence": "float"
    }
  ],
  "figures": [
    {
      "figure_id": "string",
      "page": "integer",
      "bbox": {...},
      "caption": "string",
      "image_path": "string",
      "confidence": "float"
    }
  ],
  "text": [
    {
      "chunk_id": "string",
      "page": "integer",
      "bbox": {...},
      "content": "string",
      "semantic_type": "string"
    }
  ]
}
```

## ğŸš€ Usage (After Phase 1)

### **Basic Extraction**
```python
from extraction_v14_P1 import ExtractionPipeline

pipeline = ExtractionPipeline(config_path="config/extraction_v14_P1_config.yaml")
results = pipeline.extract(pdf_path="document.pdf")

# Save results
pipeline.save_results(results, output_path="extraction_results.json")
```

### **Parallel Processing**
```python
from extraction_v14_P1 import ParallelExtractionPipeline

pipeline = ParallelExtractionPipeline(
    config_path="config/extraction_v14_P1_config.yaml",
    num_workers=8
)
results = pipeline.extract_batch(pdf_paths=["doc1.pdf", "doc2.pdf"])
```

## ğŸ”— Integration with Pipeline 2

**Output Contract**: Pipeline 1 produces `extraction_results_v1.json` conforming to schema `schemas/extraction/extraction_results_v1.json`.

**Pipeline 2 Consumption**: RAG preparation pipeline reads this JSON and creates semantic chunks with relationships.

## ğŸ“ Configuration

See `config/extraction_v14_P1_config.yaml` for configuration options:
- Detection methods (enable/disable YOLO, Docling, PyMuPDF)
- Extraction parameters (thresholds, batch sizes)
- Parallel processing (number of workers)
- Output formats (JSON, JSONL, both)

## ğŸ§ª Testing

```bash
# Unit tests
pytest tests/test_detection.py
pytest tests/test_extraction.py

# Integration tests
pytest tests/test_integration.py

# Full pipeline test
python tests/test_full_pipeline.py --input tests/data/sample.pdf
```

## ğŸ“š Documentation

- **Detection Methods**: `docs/detection_methods.md`
- **Extraction Methods**: `docs/extraction_methods.md`
- **Schema Reference**: `docs/schema_reference.md`
- **Migration Notes**: `docs/v13_migration_notes.md`

---

**Status**: Phase 0 - Foundation setup in progress
**Next**: Phase 1 - Implement core extraction pipeline
